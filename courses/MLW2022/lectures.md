| [MATH80629A](main.md) | [Lectures](lectures.md) | [Homework](homework.md) | [Lab](lab.md) | [Project](project.md) | [Office hour](office_hr.md)
# Machine Learning for Large-Scale Data Analysis and Decision Making (MATH80629A): Winter 2022

## Lecture Schedule
___
1- <span style="font-size:1em;">Week 1 (January 5): **Class introduction and math review**</span>
- **Lecture**: [Slides](https://github.com/gfarnadi/gfarnadi.github.io/blob/master/courses/MLW2022/lecture_files/slides_intro.pdf)
- **Reading**: 
  * [Prologue to The Master Algorithm](http://homes.cs.washington.edu/~pedrod/Prologue.pdf)
  * [Chapter 1 of ESL](https://web.stanford.edu/~hastie/Papers/ESLII.pdf)
  * For Math review: Check [here](http://www.cs.toronto.edu/~lcharlin/courses/80-629/math_resources.html)

___
2- <span style="font-size:1em;">Week 2 (January 12): **Machine learning fundamentals**</span> 
- **Lecture**: [Slides](http://www.cs.toronto.edu/~lcharlin/courses/80-629/slides_ml-fundamentals.pdf)
- **Capsules**:  
  * [Learning Problem](https://youtu.be/XHjYLAooCQI) [14:40]
  * [Types of Experiences](https://youtu.be/bUrw6MWiI7E) [13:15]
  * [A first Supervised Model](https://www.youtube.com/watch?v=fu8IBbPREBg) [8:03]
  * [Model Evaluation](https://youtu.be/jB69v09vrn8) [15:26]
  * [Regularization](https://www.youtube.com/watch?v=SFzhFrWOTEI) [4:09]
  * [Model Validation](https://www.youtube.com/watch?v=WoFGyFvyoeo) [3:08]
  * [Bias / Variance tradeoff](https://www.youtube.com/watch?v=L5Hehy9s8SI) [11:50]
- **Reading**:  
  * [Chapter 5 of Deep Learning](http://www.deeplearningbook.org/contents/ml.html). You can skip 5.4 (except 5.4.4) to 5.10.  
  
___
3- <span style="font-size:1em;">Week 3 (January 19): **Supervised learning algorithms**</span> 
- **Lecture**: [Slides](http://www.cs.toronto.edu/~lcharlin/courses/80-629/slides_supervised.pdf)
- **Capsules**: 
  * [Nearest Neighbor](https://youtu.be/wrpB9mxmhJc) [19:05]
  * [Linear Classification](https://youtu.be/Kv8Ab2I_7CM) [15:26]
  * [Introduction to Probabilistic Models (for Classification)](https://youtu.be/CnJTkeJpJLY) [11:55]
  * [The Naive Bayes Model](https://youtu.be/8L2ZM20BdoA) [24:28]
  * [Naive Bayes Example](https://youtu.be/xg8wZOr6zrY) [9:26]
- **Reading**: Sections 4.1-4.3, 4.5 of The Elements of Statistical Learning (available [online](https://web.stanford.edu/~hastie/ElemStatLearn/)), Sections 3.5 and 4.2 of Machine Learning (K. Murphy)

___
4- <span style="font-size:1em;">Week 4 (January 26): **Python for scientific computations and machine learning**</span> 
- ML Lab location: Laboratoire Lachute
- **Lecture**: [Tutorial](https://colab.research.google.com/github/lcharlin/80-629/blob/master/week4-PracticalSession/Introduction_to_ML.ipynb)
- solution: [solution](https://colab.research.google.com/github/lcharlin/80-629/blob/master/week4-PracticalSession/Introduction_to_ML_Solutions.ipynb)

___
5- <span style="font-size:1em;">Week 5 (February 2): **Neural networks and deep learning**</span> 
- **Lecture**: [Slides](http://www.cs.toronto.edu/~lcharlin/courses/80-629/slides_nn.pdf)
- **Capsules**: 
  * [From linear classification to neural networks](https://youtu.be/Bs6NA2gGz78) [19:28]
  * [Training neural networks](https://youtu.be/c47a3YxIG7k) [20:14]
  * [Learning representations](https://youtu.be/N_JU7egyGGA)  [13:40]
  * [Neural networks hyperparameters](https://youtu.be/5axp1O299qM)  [25:20]
  * [Neural networks takeaways](https://youtu.be/Nqs-C7wBVQo) [7:00]
- **Reading**:
  * Sections [6.1--6.3 and 6.5](http://www.deeplearningbook.org/contents/mlp.html) (stop at 6.5.4) of Deep Learning (the book).  
  * Optional: Chapter 11 of the Elements of Statistical Learning.

___
6- <span style="font-size:1em;">Week 6 (February 9): **Recurrent Neural networks and Convolutional neural networks**</span> 
- **Lecture**: [Slides](http://www.cs.toronto.edu/~lcharlin/courses/80-629/slides_rnn-cnn.pdf)
- **Capsules**: 
  * [Modelling Sequential Data](https://youtu.be/Ra_n9vJ89wM) [8:42]
  * [Practical Overview of RNNs](https://youtu.be/2euWyjhO0GM) [29:32]
  * [RNNs for language modelling](https://youtu.be/K-l8zCBuJbM) [15:13]
  * [Overview of CNNs](https://youtu.be/EVZOThR2q1I) [13:30]
  * [Convolutions and Pooling](https://youtu.be/L8tbxFKKoVw) [26:00]
  * [Conclusions and Practical remarks](https://youtu.be/mA71uUtkcXw) [9:17]
- **Reading**: Required readings: Sections 10, 10.1, 10.2 (skim 10.2.2, skip 10.2.3), and 10.7. Sections 9, 9.1, 9.2, 9.3 (9.11 for fun). Both from [the Deep Learning book](http://www.deeplearningbook.org/).

___
7- <span style="font-size:1em;">Week 7 (February 16): **Unsupervised learning**</span> 
- **Lecture**: [Slides](http://www.cs.toronto.edu/~lcharlin/courses/80-629/slides_unsupervised.pdf)
- **Capsules**: 
  * [Introduction to unsupervised learning](https://youtu.be/z_PcTBDHvOs) [8:17]
  * [K-means clustering](https://youtu.be/9EFWKAQ3TSs) [41:58] (there's a natural break at 22:28)
  * [GMMs for clustering](https://youtu.be/OyK4tX2hjMc) [17:52]
  * [Beyond Clustering](https://youtu.be/zVoi--FTiYk) [14:42]
- **Reading**: Section 14.3 (skip 14.3.5 and 14.3.12) of the Elements of Statistical Learning. Optional: Chapter 9 of the Pattern Recognition and Machine Learning. 

___
8- <span style="font-size:1em;">Week 8 (February 23): **Reading week**</span> 
- No lectures

___
9- <span style="font-size:1em;">Week 9 (March 2): **Project meetings**</span> 
- No lectures

___
10- <span style="font-size:1em;">Week 10 (March 9): **Parallel computational paradigms for large-scale data processing**</span>
- **Lecture**: [Slides](http://www.cs.toronto.edu/~lcharlin/courses/80-629/slides_largeScale.pdf)
- **Capsules**: 
  * [Introduction to Distributed Computing for ML](https://youtu.be/CtYOBS9pDvg) [19:35]
  * [MapReduce](https://youtu.be/U3FLRYH3R5Q) [17:41]
  * [Spark](https://www.youtube.com/watch?v=4gOdejqyHng) [17:37]

___
11- <span style="font-size:1em;">Week 11 (March 16): **Trustworthy Machine Learning  & Recommender systems**</span> 
- **Lecture**: [slides](https://github.com/gfarnadi/gfarnadi.github.io/blob/master/courses/MLW2022/lecture_files/Week11_summary.pdf)
- **Reading**: Chapters 1 through 4, Aggarwal, Charu C. [Recommender Systems: the Textbook](https://hecmontreal.on.worldcat.org/v2/oclc/946011635). Cham: Springer, 2016

___
12- <span style="font-size:1em;">Week 12 (March 23): **Sequential decision making I**</span> 
- **Lecture**: [Slides](http://www.cs.toronto.edu/~lcharlin/courses/80-629/slides_rl.pdf)
- **Capsules**: 
  * [Motivating RL](https://youtu.be/V2WrKWyiPoQ) [8:22]
  * [Planning with MDPs](https://youtu.be/FwQQCSL5I_Y) [12:16]
  * [MDP objective](https://youtu.be/3vX-J61A8NQ) [14:16]
  * [Algorithms for solving MDPs](https://youtu.be/HBTyOjt4QBk) [17:51]: Note: In this capsule, there is a mistake in the second equation of the policy iteration algorithm (the transition should be given a and not Ï€(s)), the slides have been corrected (see slides 47 and 48)
- **Reading**: Optional: [Demo of the policy iteration algorithm](https://www.cs.toronto.edu/~lcharlin/courses/80-629/reinforcejs/gridworld_dp.html) (from Andrej Karpathy)

___
13- <span style="font-size:1em;">Week 13 (March 30): **Sequential decision making II**</span> 
- **Lecture**: [Slides](http://www.cs.toronto.edu/~lcharlin/courses/80-629/slides_rl2.pdf)
- **Capsules**: 
  * [Introduction to RL](https://www.youtube.com/watch?v=VnZ4558bXys) [13:31]
  * [A first RL algorithm](https://www.youtube.com/watch?v=EYeACgMxHVk) [17:13]
  * [RL Algorithms for Control](https://www.youtube.com/watch?v=PeGnFc5S-f4) [21:10]
- **Reading**: Required reading: Sections 1 through 4 from this [Survey](https://www.jair.org/index.php/jair/article/download/10166/24110/), Chapters 1,3,4, and 6 from [Reinforcement Learning: An Introduction](http://incompleteideas.net/book/the-book.html). Optional: [Demo of the TD algorithm](https://www.cs.toronto.edu/~lcharlin/courses/80-629/reinforcejs/gridworld_td.html) (from Andrej Karpathy)

___
14- <span style="font-size:1em;">Week 14 (April 6): **Class Project presentation**</span>
* Room: TPA

___
15- <span style="font-size:1em;">Week 15 (April 13)</span>
* Final exam: TBA
* Past exam examples: [Fall 2018](http://www.cs.toronto.edu/~lcharlin/courses/80-629/exam_80629_A18.pdf), [Fall 2020](http://www.cs.toronto.edu/~lcharlin/courses/80-629/examen_80629_A20.pdf) (French)

